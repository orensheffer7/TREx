{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "import itertools\n",
    "import math\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "\n",
    "import sys\n",
    "sys.path.append('./')\n",
    "import holoclean\n",
    "from detect import NullDetector, ViolationDetector\n",
    "from repair.featurize import *\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def random_combination(iterable, r):\n",
    "    \"Random selection from itertools.combinations(iterable, r)\"\n",
    "    pool = tuple(iterable)\n",
    "    n = len(pool)\n",
    "    indices = sorted(random.Random(time.time()).sample(range(n), r))\n",
    "    return tuple(pool[i] for i in indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Holoclean Functions\n",
    "### #TODO: Create an abstract \"CleaningAlgorithm\" class and make holoclean and naiveAlgo objects inherit from them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive2(df, constraints):\n",
    "    df_c = df.copy()           \n",
    "    if 3 in constraints:\n",
    "        for i, r in df_c.iterrows():\n",
    "            if r.City != \"NULL\" and r.County != \"NULL\":\n",
    "                errors = df_c[(df_c.City == r.City) & (df_c.County != r.County) & (df_c.County != \"NULL\")]\n",
    "                if errors.shape[0] > 0:\n",
    "                    c = collections.Counter(df_c[df_c.City == r.City].County)\n",
    "                    if \"NULL\" in c:\n",
    "                        c.pop(\"NULL\")\n",
    "                    if len(c) > 0:\n",
    "                        if c.most_common(1)[0][1] > 1:\n",
    "                            df_c[\"County\"][i] = c.most_common(1)[0][0]\n",
    "                        \n",
    "\n",
    "    return df_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### HoloClean #####\n",
    "\n",
    "def create_constraints_file(constraints_path, relevant_attr):\n",
    "    '''\n",
    "    For Holoclean every contraint should only include real columns from the table. \n",
    "    So there is a need to create a custom constraints file for every table.\n",
    "    '''\n",
    "    with open(constraints_path) as fr:\n",
    "        attributes_to_keep = set()\n",
    "        constraints_to_keep = set()\n",
    "        for line in fr:\n",
    "            for attr in relevant_attr:\n",
    "                attributes_to_keep.add(attr)\n",
    "                if attr in line:\n",
    "                    constraints_to_keep.add(line)\n",
    "                    for item in line.split(\"t2.\")[1:]:\n",
    "                        if \"IQ\" in item and attr in item:\n",
    "                            attributes_to_keep.add(item.split(\")\")[0])\n",
    "    with open('./temp_constraints.txt', \"w+\") as fw:\n",
    "        for c in constraints_to_keep:\n",
    "            if \"\\n\" in c:\n",
    "                fw.write(c)\n",
    "            else:\n",
    "                fw.write(c + \"\\n\")\n",
    "    return attributes_to_keep\n",
    "\n",
    "\n",
    "def holoclean_init(data_df):\n",
    "    '''\n",
    "    #TODO: Find optimal parameters. Maybe function of something?\n",
    "    '''\n",
    "    hc = holoclean.HoloClean(\n",
    "        db_name='holo',\n",
    "        domain_thresh_1=0.1,\n",
    "        domain_thresh_2=0,\n",
    "        weak_label_thresh=0.5,\n",
    "        max_domain=10000,\n",
    "        cor_strength=0.05,\n",
    "        nb_cor_strength=0.3,\n",
    "        epochs=20,\n",
    "        weight_decay=0.01,\n",
    "        learning_rate=0.05,\n",
    "        threads=1,\n",
    "        batch_size=1,\n",
    "        verbose=False,\n",
    "        timeout=1*60000,\n",
    "        feature_norm=False,\n",
    "        weight_norm=False,\n",
    "        print_fw=False\n",
    "    ).session\n",
    "\n",
    "    hc.load_data('Name', data_df)\n",
    "    hc.load_dcs('./temp_constraints.txt')\n",
    "    hc.ds.set_constraints(hc.get_dcs())\n",
    "    hc.setup_domain(list(data_df.columns))\n",
    "    return hc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition (list_in, n):\n",
    "    random.Random(time.time()).shuffle(list_in)\n",
    "    n = int(n)\n",
    "    return [list_in[i::n] for i in range(n)]\n",
    "\n",
    "def holoclean_detect(hc):\n",
    "    detectors = [NullDetector(), ViolationDetector()]\n",
    "    featurizers = [\n",
    "        InitAttrFeaturizer(),\n",
    "        OccurAttrFeaturizer(),\n",
    "        FreqFeaturizer(),\n",
    "        ConstraintFeaturizer(),\n",
    "    ]\n",
    "    \n",
    "    hc.detect_errors(detectors)\n",
    "    hc.repair_errors(featurizers)\n",
    "\n",
    "    return hc\n",
    "\n",
    "def run_holoclean(df, constraints_path, columns):\n",
    "    relevant_attributes = create_constraints_file(constraints_path, columns)\n",
    "    print(relevant_attributes)\n",
    "    df_in = df.copy()\n",
    "    df_in = df_in[relevant_attributes]\n",
    "    hc = holoclean_init(df_in)\n",
    "    hc = holoclean_detect(hc)\n",
    "    return hc.ds.repaired_data.df    # This is only for holoclean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive(df, constraints):\n",
    "    df_c = df.copy()\n",
    "    if 1 in constraints:\n",
    "        for i, r in df_c.iterrows():\n",
    "            if r.Team != \"NULL\" and r.City != \"NULL\":\n",
    "                errors = df_c[(df_c.Team == r.Team) & (df_c.City != r.City) & (df_c.City != \"NULL\")]\n",
    "                if errors.shape[0] > 0:\n",
    "                    c = collections.Counter(df_c[df_c.Team == r.Team].City)\n",
    "                    if \"NULL\" in c:\n",
    "                        c.pop(\"NULL\")\n",
    "                    if len(c) > 0:\n",
    "                        if c.most_common(1)[0][1] > 1:\n",
    "                            df_c[\"City\"][i] = c.most_common(1)[0][0] \n",
    "\n",
    "    if 2 in constraints:\n",
    "        for i, r in df_c.iterrows():\n",
    "            if r.League != \"NULL\" and r.Country != \"NULL\":\n",
    "                errors = df_c[(df_c.League == r.League) & (df_c.Country != r.Country) & (df_c.Country != \"NULL\")]\n",
    "                if errors.shape[0] > 0:\n",
    "                    c = collections.Counter(df_c[df_c.League == r.League].Country)\n",
    "                    if \"NULL\" in c:\n",
    "                        c.pop(\"NULL\")\n",
    "                    if len(c) > 0:\n",
    "                        if c.most_common(1)[0][1] > 1:\n",
    "                            df_c[\"Country\"][i] = c.most_common(1)[0][0]\n",
    "                                   \n",
    "                        \n",
    "    if 3 in constraints:\n",
    "        for i, r in df_c.iterrows():\n",
    "            if r.City != \"NULL\" and r.County != \"NULL\":\n",
    "                errors = df_c[(df_c.City == r.City) & (df_c.County != r.County) & (df_c.County != \"NULL\")]\n",
    "                if errors.shape[0] > 0:\n",
    "                    c = collections.Counter(df_c[df_c.City == r.City].County)\n",
    "                    if \"NULL\" in c:\n",
    "                        c.pop(\"NULL\")\n",
    "                    if len(c) > 0:\n",
    "                        if c.most_common(1)[0][1] > 1:\n",
    "                            df_c[\"County\"][i] = c.most_common(1)[0][0]\n",
    "\n",
    "\n",
    "    \n",
    "    return df_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator as op\n",
    "from functools import reduce\n",
    "\n",
    "def ncr(n, r):\n",
    "    r = min(r, n-r)\n",
    "    numer = reduce(op.mul, range(n, n-r, -1), 1)\n",
    "    denom = reduce(op.mul, range(1, r+1), 1)\n",
    "    return numer // denom  # or / in Python 2\n",
    "\n",
    "def nCr(n,r):\n",
    "    f = math.factorial\n",
    "    return f(n) / f(r) / f(n-r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jefferson\n",
      "jxffxrson\n",
      "Time took for repeat 50 is: 165.14221453666687\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "m = 50\n",
    "df = pd.read_csv('./testdata/hospital_100_2.csv')\n",
    "constraints_path = './testdata/hospital_constraints.txt'\n",
    "constraints_for_alg = [1, 2, 3]\n",
    "start = time.time()\n",
    "# df = pd.read_csv('./testdata/La_liga2.csv')\n",
    "# constraints_path = './testdata/La_liga_constraints.txt'\n",
    "\n",
    "# data = [\n",
    "#     [\"Barcelona F.C.\", \"La Liga\", \"Barcelona\", \"Spain\"],\n",
    "#     [\"Real\", \"La Liga\", \"Madrid\", \"Espana\"],\n",
    "#     [\"Athletico\", \"La Liga\", \"Madrid\", \"Spain\"],\n",
    "#     [\"Athletico\", \"Spanish_League\", \"Madrid\", \"Spain\"],\n",
    "#     [\"Real\", \"La Liga\", \"Madrid\", \"Spain\"],\n",
    "# ]\n",
    "\n",
    "\n",
    "# df = pd.DataFrame(data, columns=[\"Team\", \"League\", \"City\", \"Country\"])\n",
    "\n",
    "df_copy = df.copy()\n",
    "\n",
    "cell_repair = (40, \"County\")\n",
    "row_repair, col_repair = cell_repair[0], cell_repair[1]\n",
    "column = cell_repair[1]\n",
    "\n",
    "before_fix = df_copy[column][cell_repair[0]]\n",
    "\n",
    "\n",
    "#######              1           ################\n",
    "# df_repair = run_holoclean(df_copy, constraints_path, [column])\n",
    "df_repair = naive2(df_copy, [1, 2, 3])\n",
    "#######              1           ################\n",
    "\n",
    "\n",
    "after_fix = df_repair[column][cell_repair[0]]\n",
    "\n",
    "print(after_fix)\n",
    "print(df_copy[column][cell_repair[0]])\n",
    "\n",
    "relevant_rows = df_repair[df_repair[column]==df_repair[column][cell_repair[0]]]\n",
    "relevant_attributes = create_constraints_file(constraints_path, [column])\n",
    "# relevant_attributes = df.columns\n",
    "cells = list(itertools.product(relevant_rows.index, relevant_attributes))\n",
    "\n",
    "cells.remove(cell_repair)\n",
    "cells_copy = cells.copy()\n",
    "\n",
    "memo_dict = {}\n",
    "for cell in cells:\n",
    "    memo_dict[str(cell)] = {\"is_fix_with_cell\" : {}, \"is_fix_without_cell\" : {}}\n",
    "\n",
    "weights = []\n",
    "params = []\n",
    "    \n",
    "# start = time.time()\n",
    "# r = np.random.binomial(len(cells),0.5)\n",
    "# p = 0.0\n",
    "# r = int(len(cells) * p)\n",
    "\n",
    "for i in range(m):\n",
    "    p = random.uniform(0.2, 0.8)\n",
    "#     p = 1.0\n",
    "    r = np.random.binomial(len(cells),p)\n",
    "    if 1:\n",
    "        comb = set(random_combination(cells, r))\n",
    "        comb_bar = set(cells) - comb\n",
    "        df_c = df.copy()\n",
    "        \n",
    "        S = r\n",
    "        T = len(cells)\n",
    "\n",
    "        for cell in comb:\n",
    "            df_c[cell[1]][cell[0]] = str(cell)\n",
    "\n",
    "        #######              2           ################\n",
    "        # df_repair = run_holoclean(df_copy, constraints_path, [column])\n",
    "        df_repair = naive2(df_copy, [1, 2, 3])\n",
    "        #######              2           ################\n",
    "\n",
    "        is_repair_without = (df_repair[col_repair][row_repair] == after_fix)\n",
    "#         print(\"Was it fixed with comb hided?   :   \" + str(is_repair_without))\n",
    "        \n",
    "        for cell in comb:\n",
    "            memo_dict[str(cell)][\"is_fix_without_cell\"][i] = is_repair_without\n",
    "        for cell in comb_bar:\n",
    "            memo_dict[str(cell)][\"is_fix_with_cell\"][i] = is_repair_without\n",
    "        \n",
    "        if not is_repair_without:\n",
    "            factor = pow(p,S-1)*pow(1-p, T-S+1)*T*ncr(T-1,S-1)\n",
    "            for cell in comb:\n",
    "                df_c[cell[1]][cell[0]] = df[cell[1]][cell[0]] \n",
    "                \n",
    "                #######              3           ################\n",
    "                # df_repair = run_holoclean(df_copy, constraints_path, [column])\n",
    "                df_repair = naive2(df_copy, [1, 2, 3])\n",
    "                #######              3           ################\n",
    "\n",
    "                is_repair_with = (df_repair2[col_repair][row_repair] == after_fix)\n",
    "                memo_dict[str(cell)][\"is_fix_with_cell\"][i] = is_repair_with\n",
    "                df_c[cell[1]][cell[0]] = str(cell)\n",
    "            for cell in comb_bar:\n",
    "                memo_dict[str(cell)][\"is_fix_without_cell\"][i] = True\n",
    "#             r = r - math.ceil(len(cells)*0.05)\n",
    "#             p = p - 0.05\n",
    "        else:\n",
    "            factor = pow(p,S+1)*pow(1-p, T-S-1)*T*ncr(T-1,S+1)\n",
    "            for cell in comb_bar:\n",
    "                df_c[cell[1]][cell[0]] = str(cell)\n",
    "                \n",
    "                #######              4           ################\n",
    "                # df_repair = run_holoclean(df_copy, constraints_path, [column])\n",
    "                df_repair = naive2(df_copy, [1, 2, 3])\n",
    "                #######              4           ################\n",
    "\n",
    "\n",
    "                is_repair_with = (df_repair2[col_repair][row_repair] == after_fix)\n",
    "                memo_dict[str(cell)][\"is_fix_without_cell\"][i] = is_repair_with\n",
    "                df_c[cell[1]][cell[0]] = df[cell[1]][cell[0]]\n",
    "            for cell in comb:\n",
    "                memo_dict[str(cell)][\"is_fix_with_cell\"][i] = False\n",
    "#             r = r + math.ceil(len(cells)*0.05)\n",
    "#             p = p + 0.05\n",
    "    \n",
    "        weights.append(1 / factor)\n",
    "        params.append((S, T, p))\n",
    "#     except:\n",
    "#         print(\"!!!\")\n",
    "#         pass       \n",
    "            \n",
    "end = time.time()\n",
    "print(\"Time took for repeat {} is: \".format(m) + str(end - start))\n",
    "print(r)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"(40, 'City')!\": 21,\n",
       " \"(1, 'City')!\": 8,\n",
       " \"(42, 'City')!\": 7,\n",
       " \"(41, 'City')!\": 6,\n",
       " \"(42, 'County')!\": 6,\n",
       " \"(1, 'County')!\": 5,\n",
       " \"(41, 'County')!\": 5,\n",
       " \"(2, 'City')!\": 4,\n",
       " \"(2, 'County')!\": 3,\n",
       " \"(0, 'County')\": 0,\n",
       " \"(0, 'County')!\": 0,\n",
       " \"(0, 'City')\": 0,\n",
       " \"(0, 'City')!\": 0,\n",
       " \"(1, 'County')\": 0,\n",
       " \"(1, 'City')\": 0,\n",
       " \"(2, 'County')\": 0,\n",
       " \"(2, 'City')\": 0,\n",
       " \"(13, 'County')\": 0,\n",
       " \"(13, 'County')!\": 0,\n",
       " \"(13, 'City')\": 0,\n",
       " \"(13, 'City')!\": 0,\n",
       " \"(27, 'County')\": 0,\n",
       " \"(27, 'County')!\": 0,\n",
       " \"(27, 'City')\": 0,\n",
       " \"(27, 'City')!\": 0,\n",
       " \"(40, 'City')\": 0,\n",
       " \"(41, 'County')\": 0,\n",
       " \"(41, 'City')\": 0,\n",
       " \"(42, 'County')\": 0,\n",
       " \"(42, 'City')\": 0,\n",
       " \"(63, 'County')\": 0,\n",
       " \"(63, 'County')!\": 0,\n",
       " \"(63, 'City')\": 0,\n",
       " \"(63, 'City')!\": 0}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results= {}\n",
    "std_list = []\n",
    "for cell in cells:\n",
    "    results[str(cell)] = 0\n",
    "    results[str(cell) + \"!\"] = 0\n",
    "\n",
    "for j in range(50):\n",
    "    std_count = 0\n",
    "    for cell in cells:\n",
    "        try:\n",
    "            if not memo_dict[str(cell)][\"is_fix_without_cell\"][j] and memo_dict[str(cell)][\"is_fix_with_cell\"][j]:\n",
    "#                 results[str(cell)] += weights[j]\n",
    "                results[str(cell) + \"!\"] += 1\n",
    "                std_count += 1\n",
    "        except:\n",
    "            pass\n",
    "    std_list.append(std_count)\n",
    "        \n",
    "results\n",
    "{k: v for k, v in sorted(results.items(), key=lambda item: -item[1])}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
